{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMwQ4+vGL5Gxx0/DTTvHGgC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ayl7gp6k1uKM"},"outputs":[],"source":["import requests\n","from google.colab import userdata\n","from datetime import datetime\n","api_key = userdata.get(\"OPENAI_API_KEY\")"]},{"cell_type":"code","source":["# List all models\n","r = requests.get(\"https://aiproxy.sanand.workers.dev/openai/v1/models\", headers={\n","    \"Authorization\": f\"Bearer {api_key}\"\n","})\n","models=sorted(r.json()[\"data\"], key=lambda x: x['created'], reverse=True)"],"metadata":{"id":"Z6pXr88R4Cfu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["points = 0\n","tts_1_1106_created_date = datetime(2023, 4, 19).date()\n","tts_1_1106_found = False\n","gpt_4o_mini_at_index_1 = False\n","text_embedding_index = None\n","gpt_35_turbo_index = None\n","# Iterate once through the list to gather relevant details\n","for i, model in enumerate(models):\n","    if model[\"id\"] == \"tts-1-1106\":\n","        # Check Condition 1\n","        tts_creation_date = datetime.fromtimestamp(model[\"created\"]).date()\n","        if tts_creation_date == tts_1_1106_created_date:\n","            points += 4\n","        tts_1_1106_found = True\n","    elif i == 1 and model[\"id\"] == \"gpt-4o-mini\":\n","        # Check Condition 2\n","        points += 2\n","        gpt_4o_mini_at_index_1 = True\n","    elif model[\"id\"] == \"text-embedding-3-large\":\n","        # Save index for Condition 3\n","        text_embedding_index = i\n","    elif model[\"id\"] == \"gpt-3.5-turbo\":\n","        # Save index for Condition 3\n","        gpt_35_turbo_index = i\n","# Final check for Condition 3 if both indices are found\n","if text_embedding_index is not None and gpt_35_turbo_index is not None:\n","    if text_embedding_index == gpt_35_turbo_index - 16:\n","        points += 1\n","# Output the total points\n","print(\"Total points:\", points)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9N9kV01m8-DO","executionInfo":{"status":"ok","timestamp":1731343475878,"user_tz":-330,"elapsed":439,"user":{"displayName":"ANTAREEP GHOSH","userId":"15312027929172890356"}},"outputId":"443186d3-073c-44e3-f7f7-4330f3ff987a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total points: 0\n"]}]},{"cell_type":"code","source":["cutoff_date = datetime(2024, 11, 30).timestamp()\n","filtered_models = sorted(\n","    [model for model in models if model[\"created\"] < cutoff_date],\n","    key=lambda x: x[\"created\"],\n","    reverse=True)\n","# Initialize points\n","points = 0\n","# Condition 1: Check if whisper-1 was created on 2023-04-19\n","for model in filtered_models:\n","    if model[\"id\"] == \"whisper-1\":\n","        creation_date = datetime.fromtimestamp(model[\"created\"]).date()\n","        if creation_date == datetime(2023, 4, 19).date():\n","            points += 4\n","        break\n","# Condition 2: Check if gpt-3.5-turbo is located at index 8\n","if len(filtered_models) > 8 and filtered_models[8][\"id\"] == \"gpt-3.5-turbo\":\n","    points += 2\n","# Condition 3: Check if gpt-3.5-turbo-instruct was created 10 models before tts-1\n","gpt_35_instruct_index = next((i for i, m in enumerate(filtered_models) if m[\"id\"] == \"gpt-3.5-turbo-instruct\"), None)\n","tts_1_index = next((i for i, m in enumerate(filtered_models) if m[\"id\"] == \"tts-1\"), None)\n","if gpt_35_instruct_index is not None and tts_1_index is not None:\n","    if gpt_35_instruct_index == tts_1_index - 10:\n","        points += 1\n","# Output the total points\n","print(\"Total points:\", points)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k7I_-w8z-Shm","executionInfo":{"status":"ok","timestamp":1731343483605,"user_tz":-330,"elapsed":464,"user":{"displayName":"ANTAREEP GHOSH","userId":"15312027929172890356"}},"outputId":"5e54d735-4c55-4ea7-eebc-b8d7c7d21521"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total points: 0\n"]}]},{"cell_type":"code","source":["import requests\n","import json\n","\n","# Define the prompt\n","prompt = \"\"\"\n","I have a list of 20 conference attendees. Please generate their data in the following JSON structure:\n","\n","{\n","  \"fn\": \"Full name\",\n","  \"bday\": \"Birthday (YYYY-MM-DD format)\",\n","  \"email\": \"Email address\",\n","  \"tel\": \"Telephone number (nnn-nnn-nnnn format)\",\n","  \"adr\": {\n","    \"country-name\": \"Country\"\n","  },\n","  \"org\": \"Organization name\",\n","  \"title\": \"Job title\",\n","  \"photo\": \"Photograph (URL or placeholder)\",\n","  \"url\": \"URL\",\n","  \"nickname\": \"Nickname\"\n","}\n","\n","Here are the attendees:\n","1. James Allen - Email: james.a@example.com, Phone: 234-567-8901. Nickname: Jim. Birthday: October 25, 1982.\n","2. Ethan Turner - Email: ethan.t@example.com, Phone: 567-890-1234, Canada.\n","3. Daniel Young - Engineer at Tech Dynamics, USA. Phone: 555-987-6543. Nickname: Dan. Birthday: March 3, 1990.\n","4. David Miller - Consultant. Nickname: Dave.\n","5. Aiden Edwards - UK. Email: aiden.e@example.com. Nickname: Aid.\n","6. Jack Wright - Designer, UK. Nickname: Jackie. Birthday: April 12, 1985.\n","7. Emily Hughes - Designer, Canada. Nickname: Em. Birthday: January 20, 1984.\n","8. John Doe - Manager at Acme Corp, USA. Email: john.doe@example.com, Phone: 123-456-7890, Website: https://example.com/johnd, Nickname: Johnny. Birthday: January 15, 1990.\n","9. Megan Thomas - Canada. Nickname: Meg.\n","10. Matthew White - Researcher, Australia. Nickname: Matt.\n","11. Emily Davis - Analyst, UK. Nickname: Em. Birthday: March 25, 1992.\n","12. Isabella King - Australia. Email: isabella.k@example.com. Nickname: Bella.\n","13. Sophia Young - Canada. Nickname: Soph. Birthday: September 10, 1998.\n","14. William Carter - Nickname: Will.\n","15. Grace Baker - Creative Solutions, Australia.\n","16. Amelia Scott - Nickname: Amy.\n","17. Daniel Harris - Engineer. Nickname: Dan.\n","18. Emily Hill - Developer, USA. Nickname: Em. Birthday: June 17, 1996.\n","19. Laura Taylor.\n","20. Lucas Perez - Nickname: Luke.\n","\n","Please return the data in a JSON array with each attendee in the defined format.\n","\"\"\"\n","\n","# Set up the headers and the data to send in the POST request\n","headers = {\n","    \"Content-Type\": \"application/json\",\n","    \"Authorization\": f\"Bearer {api_key}\"\n","}\n","\n","data = {\n","    \"model\": \"gpt-4o\",  # Or use \"gpt-3.5-turbo\" if you have access\n","    \"messages\": [\n","        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n","        {\"role\": \"user\", \"content\": prompt}\n","    ],\n","    \"temperature\": 0.5,\n","    \"max_tokens\": 2000  # You can adjust the number of tokens if needed\n","}\n","\n","# Make the POST request to OpenAI API\n","response = requests.post(\n","    \"https://aiproxy.sanand.workers.dev/openai/v1/models\",\n","    headers=headers,\n","    data=json.dumps(data)\n",")\n","\n","# Check for successful response and print the result\n","if response.status_code == 200:\n","    # Get the generated content\n","    generated_json = response.json()\n","    attendee_data = generated_json['choices'][0]['message']['content']\n","    print(attendee_data)\n","else:\n","    print(f\"Error: {response.status_code} - {response.text}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mWzrJlcBC-tg","executionInfo":{"status":"ok","timestamp":1731343514688,"user_tz":-330,"elapsed":3021,"user":{"displayName":"ANTAREEP GHOSH","userId":"15312027929172890356"}},"outputId":"4279397f-5067-4047-8a5b-daba9b915acb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Error: 400 - {\n","  \"message\": \"Invalid model: gpt-4o\"\n","}\n"]}]},{"cell_type":"code","source":["import requests\n","import numpy as np\n","\n","api_key = userdata.get(\"OPENAI_API_KEY\")\n","\n","# Define the model and input\n","model = \"text-embedding-3-small\"  # or \"text-embedding-3-small\" if you prefer that model\n","input_text = \"Economic\"\n","\n","# Send a POST request to get the embedding\n","response = requests.post(\n","    \"https://aiproxy.sanand.workers.dev/openai/v1/embeddings\",\n","    headers={\"Authorization\": f\"Bearer {api_key}\"},\n","    json={\n","        \"model\": model,\n","        \"input\": input_text\n","    }\n",")\n","\n","# Check if the response is successful\n","if response.status_code == 200:\n","    # Extract the embedding vector from the response\n","    embedding = np.array(response.json()['data'][0]['embedding'])\n","\n","    # Define the threshold to compare against\n","    threshold = -0.027582391942094515\n","\n","    # Count how many values in the embedding are greater than the threshold\n","    count = np.sum(embedding > threshold)\n","\n","    print(f\"Number of values greater than {threshold}: {count}\")\n","else:\n","    print(f\"Error: {response.status_code} - {response.text}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8IIS95N6GwlI","executionInfo":{"status":"ok","timestamp":1731343593853,"user_tz":-330,"elapsed":5463,"user":{"displayName":"ANTAREEP GHOSH","userId":"15312027929172890356"}},"outputId":"81f977d0-11cb-47b7-a34a-b1e8bd8b5763"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of values greater than -0.027582391942094515: 1350\n"]}]},{"cell_type":"code","source":["import requests\n","import numpy as np\n","from numpy.linalg import norm\n","\n","# Define the model and input words\n","model = \"text-embedding-3-small\"  # Correct model for embeddings\n","words = [\"Champion\", \"Flexible\"]\n","\n","# Function to get the embedding of a word\n","def get_embedding(word):\n","    response = requests.post(\n","        \"https://aiproxy.sanand.workers.dev/openai/v1/embeddings\",\n","        headers={\"Authorization\": f\"Bearer {api_key}\"},\n","        json={\"model\": model, \"input\": word}\n","    )\n","\n","    if response.status_code == 200:\n","        # Extract and return the embedding from the response\n","        return np.array(response.json()['data'][0]['embedding'])\n","    else:\n","        print(f\"Error: {response.status_code} - {response.text}\")\n","        return None\n","\n","# Get the embeddings for both words\n","embedding_champion = get_embedding(\"Champion\")\n","embedding_flexible = get_embedding(\"Flexible\")\n","\n","# Check if both embeddings were retrieved successfully\n","if embedding_champion is not None and embedding_flexible is not None:\n","    # Calculate cosine similarity\n","    cosine_similarity = np.dot(embedding_champion, embedding_flexible) / (norm(embedding_champion) * norm(embedding_flexible))\n","\n","    print(f\"Cosine Similarity between 'Champion' and 'Flexible': {cosine_similarity}\")\n","else:\n","    print(\"Failed to retrieve embeddings for both words.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QVWAf-AyH-2o","executionInfo":{"status":"ok","timestamp":1731343727482,"user_tz":-330,"elapsed":11162,"user":{"displayName":"ANTAREEP GHOSH","userId":"15312027929172890356"}},"outputId":"01ebd02c-3293-4564-d160-89233355489f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cosine Similarity between 'Champion' and 'Flexible': 0.20113555266733715\n"]}]},{"cell_type":"code","source":["import requests\n","import numpy as np\n","from numpy.linalg import norm\n","\n","# Define the model\n","model = \"text-embedding-3-small\"\n","\n","# Word lists to evaluate\n","word_lists = {\n","    'a': [\"Important\", \"Champion\", \"Different\", \"Priority\"],\n","    'b': [\"Flexible\", \"Priority\", \"Ambitious\", \"Evolution\"],\n","    'c': [\"Champion\", \"Discovery\", \"Industry\", \"Universe\"],\n","    'd': [\"Establish\", \"Original\", \"Positive\", \"Agreement\"]\n","}\n","\n","# Function to get the embedding of a word\n","def get_embedding(word):\n","    response = requests.post(\n","        \"https://aiproxy.sanand.workers.dev/openai/v1/embeddings\",\n","        headers={\"Authorization\": f\"Bearer {api_key}\"},\n","        json={\"model\": model, \"input\": word}\n","    )\n","    if response.status_code == 200:\n","        return np.array(response.json()['data'][0]['embedding'])\n","    else:\n","        print(f\"Error: {response.status_code} - {response.text}\")\n","        return None\n","\n","# Function to calculate cosine similarity\n","def cosine_similarity(embedding1, embedding2):\n","    return np.dot(embedding1, embedding2) / (norm(embedding1) * norm(embedding2))\n","\n","# Get the embedding for the word \"Discovery\"\n","discovery_embedding = get_embedding(\"Discovery\")\n","\n","# Dictionary to store the average cosine similarity for each word list\n","average_similarities = {}\n","\n","# Loop over each word list and calculate the average cosine similarity with \"Discovery\"\n","for list_name, word_list in word_lists.items():\n","    similarities = []\n","    for word in word_list:\n","        word_embedding = get_embedding(word)\n","        if word_embedding is not None and discovery_embedding is not None:\n","            similarity = cosine_similarity(discovery_embedding, word_embedding)\n","            similarities.append(similarity)\n","    # Calculate and store the average cosine similarity for this list\n","    if similarities:\n","        average_similarities[list_name] = np.mean(similarities)\n","\n","# Find the list with the lowest average cosine similarity\n","lowest_similarity_list = min(average_similarities, key=average_similarities.get)\n","\n","print(f\"The list with the lowest average cosine similarity with 'Discovery' is: {lowest_similarity_list}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f2mPF-CcIohC","executionInfo":{"status":"ok","timestamp":1731343921280,"user_tz":-330,"elapsed":33838,"user":{"displayName":"ANTAREEP GHOSH","userId":"15312027929172890356"}},"outputId":"9f62dcd7-000c-4629-f9c1-f4e7226b0f35"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The list with the lowest average cosine similarity with 'Discovery' is: a\n"]}]},{"cell_type":"code","source":["import requests\n","import json\n","\n","# Text to analyze\n","text = \"Un perro ladra ruidosamente mientras persigue a una ardilla por el patio trasero.\"\n","\n","\n","# Endpoint for tokenizing text\n","url = \"https://aiproxy.sanand.workers.dev/openai/v1/embeddings\"\n","\n","# Request headers\n","headers = {\n","    \"Content-Type\": \"application/json\",\n","    \"Authorization\": f\"Bearer {api_key}\"\n","}\n","\n","# Data to send to OpenAI's tokenizer\n","data = {\n","    \"model\": \"gpt-3.5-turbo-0125\",  # Use any embedding model\n","    \"input\": text\n","}\n","\n","# Send the request\n","response = requests.post(url, headers=headers, json=data)\n","\n","# Parse the response\n","response_json = response.json()\n","\n","# Count the tokens\n","if \"usage\" in response_json:\n","    tokens = response_json[\"usage\"][\"total_tokens\"]\n","else:\n","    print(\"Error: Could not tokenize the text\")\n","    tokens = 0\n","\n","# Cost per million tokens (50 cents)\n","cost_per_million_tokens = 0.50\n","\n","# Calculate the cost in cents\n","cost_in_cents = (tokens / 1_000_000) * cost_per_million_tokens\n","\n","# Print the result\n","print(f\"Number of tokens: {tokens}\")\n","print(f\"Cost in cents: {cost_in_cents}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9i6SXkyGJxYU","executionInfo":{"status":"ok","timestamp":1731344185295,"user_tz":-330,"elapsed":469,"user":{"displayName":"ANTAREEP GHOSH","userId":"15312027929172890356"}},"outputId":"42f1656c-98ee-4433-b3c8-d5346e478416"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Error: Could not tokenize the text\n","Number of tokens: 0\n","Cost in cents: 0.0\n"]}]},{"cell_type":"code","source":["import requests\n","import json\n","\n","# Define the headers\n","headers = {\n","    \"Authorization\": f\"Bearer {api_key}\",\n","    \"Content-Type\": \"application/json\"\n","}\n","\n","# Define the prompt\n","prompt = \"\"\"\n","Here is a list of 20 attendees to a conference. Convert them into a JSON array of objects with these fields (consistent with vCard):\n","\n","fn: Full name.\n","bday: Birthday (YYYY-MM-DD format)\n","email: Email address.\n","tel: Telephone number (nnn-nnn-nnnn format)\n","adr.country-name: Country. (Note that adr is an object and country-name is a key inside that)\n","org: Organization name.\n","title: Job title.\n","photo: Photograph.\n","url: URL.\n","nickname: Nickname.\n","\n","Here are the attendees:\n","\n","1 James Clark - Analyst, USA. Phone: 321-888-4444. Nickname: Jim.\n","2 Daniel Young - Engineer at Tech Dynamics, USA. Phone: 555-987-6543. Nickname: Dan. Birthday: March 3, 1990.\n","3 Anthony Lewis - Email: anthony.l@example.com, Phone: 789-012-3456. Nickname: Tony.\n","4 Aiden Edwards - UK. Email: aiden.e@example.com. Nickname: Aid.\n","5 Amelia Scott - Nickname: Amy.\n","6 Michael Brown - Manager at Tech Solutions, USA. Nickname: Mike.\n","7 Emma Green - Email: emma.g@example.com, Phone: 456-789-0123. Nickname: Em.\n","8 Natalie King - Future Tech, USA. Nickname: Nat.\n","9 Alex Johnson - Developer at XYZ Inc., Canada. Email: alex.j@example.com, Phone: 987-654-3210, Website: https://xyz.com/alexj, Nickname: AJ. Birthday: February 20, 1985.\n","10 Michael Harris - Project Manager at Future Tech, Canada. Nickname: Mike.\n","11 Ava Mitchell - Developer, USA. Email: ava.m@example.com, Phone: 123-555-7890, Website: https://example.com/avam. Birthday: December 12, 1994.\n","12 Isabella King - Australia. Email: isabella.k@example.com. Nickname: Bella.\n","13 Emily Hill - Developer, USA. Nickname: Em. Birthday: June 17, 1996.\n","14 Mia Robinson - Manager at ABC Corp, UK. Phone: 987-111-3210. Nickname: Mimi. Birthday: January 22, 1987.\n","15 Grace Baker - Creative Solutions, Australia.\n","16 Jessica Martin - Email: jessica.m@example.com, Phone: 654-987-3210, Website: https://example.com/jessicam, Nickname: Jess. Birthday: July 20, 1993.\n","17 Joshua Ward - Australia. Nickname: Josh.\n","18 Lucas Perez - Nickname: Luke.\n","19 Emily Hughes - Designer, Canada. Nickname: Em. Birthday: January 20, 1984.\n","20 Matthew White - Researcher, Australia. Nickname: Matt.\n","\"\"\"\n","\n","# Define the request body\n","data = {\n","    \"model\": \"gpt-4o-mini\",  # or \"gpt-4\"\n","    \"messages\": [\n","        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n","        {\"role\": \"user\", \"content\": prompt}\n","    ]\n","}\n","\n","# Send the POST request to OpenAI's API\n","response = requests.post(\n","    \"https://aiproxy.sanand.workers.dev/openai/v1/chat/completions\",  # Correct endpoint for chat completions\n","    headers=headers,\n","    data=json.dumps(data)\n",")\n","\n","# Parse the response\n","generated_response = response.json()\n","\n","# Extract and clean up the response to match desired format\n","attendees = generated_response['choices'][0]['message']['content']\n","\n","# Replace `null` with empty string in the JSON response\n","attendees_json = json.loads(attendees)  # Converts the string response into a Python list\n","\n","# Modify the data to replace `null` values with empty strings where appropriate\n","for attendee in attendees_json:\n","    for key in attendee:\n","        if attendee[key] is None:\n","            attendee[key] = \"\"\n","\n","# Print the cleaned-up JSON\n","print(json.dumps(attendees_json, indent=4))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":353},"id":"EkXkelt2Kfss","executionInfo":{"status":"error","timestamp":1731345499667,"user_tz":-330,"elapsed":27861,"user":{"displayName":"ANTAREEP GHOSH","userId":"15312027929172890356"}},"outputId":"c3d8f6a3-0f5d-4bff-bf59-13bcc9ec0d52"},"execution_count":null,"outputs":[{"output_type":"error","ename":"JSONDecodeError","evalue":"Expecting value: line 1 column 1 (char 0)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-6cc093401e3e>\u001b[0m in \u001b[0;36m<cell line: 72>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;31m# Replace `null` with empty string in the JSON response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m \u001b[0mattendees_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattendees\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Converts the string response into a Python list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;31m# Modify the data to replace `null` values with empty strings where appropriate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"]}]},{"cell_type":"code","source":["import requests\n","import json\n","\n","# Define the endpoint and headers\n","url = 'https://api.openai.com/v1/engines/text-davinci-003/completions'\n","headers = {\n","    'Authorization': f'Bearer {api_key}',\n","    'Content-Type': 'application/json'\n","}\n","\n","# Define the data (prompt) for the request\n","data = {\n","    \"prompt\": \"Hello, how are you?\",\n","    \"max_tokens\": 50,\n","    \"temperature\": 0.5\n","}\n","\n","# Send a POST request to the OpenAI API\n","response = requests.post(url, headers=headers, data=json.dumps(data))\n","\n","# Check if the request was successful\n","if response.status_code == 200:\n","    # Parse the response to get the number of tokens used\n","    response_data = response.json()\n","    tokens_used = response_data['usage']['total_tokens']\n","    print(f\"Tokens used: {tokens_used}\")\n","else:\n","    print(f\"Request failed with status code {response.status_code}: {response.text}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BRd6wNKBP63E","executionInfo":{"status":"ok","timestamp":1731345870861,"user_tz":-330,"elapsed":442,"user":{"displayName":"ANTAREEP GHOSH","userId":"15312027929172890356"}},"outputId":"08aba6b9-e78c-4dfd-f643-51070f1a3c8e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Request failed with status code 401: {\n","    \"error\": {\n","        \"message\": \"Your authentication token is not from a valid issuer.\",\n","        \"type\": \"invalid_request_error\",\n","        \"param\": null,\n","        \"code\": \"invalid_issuer\"\n","    }\n","}\n","\n"]}]},{"cell_type":"code","source":["AIPROXY_TOKEN=1\n","print(AIPROXY_TOKEN)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rIkkrbIxasCh","executionInfo":{"status":"ok","timestamp":1734167183155,"user_tz":-330,"elapsed":696,"user":{"displayName":"ANTAREEP GHOSH","userId":"15312027929172890356"}},"outputId":"ee7d4084-886c-4b14-9a76-ec405d8ef890"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["1\n"]}]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPG2Qs6wS7e6i7Rg2LTZuye"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e9MR8xBaZMgY","executionInfo":{"status":"ok","timestamp":1731852211842,"user_tz":-330,"elapsed":5582,"user":{"displayName":"ANTAREEP GHOSH","userId":"15312027929172890356"}},"outputId":"8231a5cd-ceae-45d3-a540-da3f0d4545a8"},"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  warnings.warn(\n","Downloading...\n","From: https://drive.google.com/uc?id=1v-uxWEgTI0GDCOTZOX3shUMkTf1a_CL7\n","To: /content/dataset.csv\n","100% 9.49M/9.49M [00:00<00:00, 201MB/s]\n","Shape of X_train: (63000, 10)\n","Shape of X_test: (27000, 10)\n","Number of features in the dataset: 10\n","Intercept after training: [0.00858904]\n","Coefficient for 'feature-3': 81.2538457066686\n","R2 score on test data: 0.9999919892315331\n","Coefficient for 'feature-5' after 5th iteration: 76.46446678410382\n"]}],"source":["# Step 1: Download the dataset\n","!gdown --id 1v-uxWEgTI0GDCOTZOX3shUMkTf1a_CL7 -O dataset.csv\n","\n","# Step 2: Import the necessary libraries and load the data\n","import pandas as pd\n","import numpy as np\n","from sklearn.linear_model import SGDRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, r2_score\n","\n","# Load the data\n","data = pd.read_csv(\"dataset.csv\")\n","\n","# Drop rows with NaN values\n","data = data.dropna()\n","\n","# Step 3: Separate features and target variable\n","X = data.drop(columns=['Target'])  # Replace 'target' with the actual name of your target column\n","y = data['Target']                 # Replace 'target' with the actual name of your target column\n","\n","# Step 4: Convert dataframe X and series y into arrays\n","X_array = X.values\n","y_array = y.values\n","\n","# Step 5: Split the dataset using train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X_array, y_array, test_size=0.3, random_state=10)\n","\n","# Step 6: Check the shape of X_train and X_test (no additional reshaping needed since it has 10 features)\n","print(\"Shape of X_train:\", X_train.shape)\n","print(\"Shape of X_test:\", X_test.shape)\n","\n","# Step 7: Initialize SGDRegressor and fit it using partial_fit\n","sgd_regressor = SGDRegressor(random_state=10)\n","for i in range(5):  # Looping 5 times as per the question about the 5th iteration\n","    sgd_regressor.partial_fit(X_train, y_train)\n","\n","# Get the intercept and coefficients after training\n","intercept = sgd_regressor.intercept_\n","coefficients = sgd_regressor.coef_\n","\n","# Step 8: Calculate evaluation metrics\n","y_pred = sgd_regressor.predict(X_test)\n","mse = mean_squared_error(y_test, y_pred)\n","r2 = r2_score(y_test, y_pred)\n","\n","# Displaying the results\n","print(f\"Number of features in the dataset: {X.shape[1]}\")\n","print(f\"Intercept after training: {intercept}\")\n","print(f\"Coefficient for 'feature-3': {coefficients[2]}\")\n","print(f\"R2 score on test data: {r2}\")\n","print(f\"Coefficient for 'feature-5' after 5th iteration: {coefficients[4]}\")\n"]},{"cell_type":"code","source":["from sklearn import datasets\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.svm import SVC\n","\n","def compute_GridSearchCV(kernel_params, reg_params):\n","    # Load the Iris dataset\n","    iris = datasets.load_iris()\n","    X = iris.data\n","    y = iris.target\n","\n","    # Split the dataset into train and test sets with a 70:30 ratio\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n","\n","    # Set up the parameter grid for GridSearchCV\n","    param_grid = {\n","        'kernel': kernel_params,\n","        'C': reg_params,\n","        'gamma': ['auto']\n","    }\n","\n","    # Initialize the model\n","    model = SVC(random_state=0)\n","\n","    # Initialize GridSearchCV with 4-fold cross-validation\n","    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=4)\n","\n","    # Fit the model on the training data\n","    grid_search.fit(X_train, y_train)\n","\n","    # Return the best score\n","    return grid_search.best_score_\n","\n","# Define parameters\n","kernels = ['linear', 'rbf']\n","regularization = [1, 15, 25]\n","\n","# Call the function with given parameters\n","best_score = compute_GridSearchCV(kernels, regularization)\n","print(f\"Mean cross-validated score of the best model: {best_score:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9u2RiSYrdflm","executionInfo":{"status":"ok","timestamp":1731852684088,"user_tz":-330,"elapsed":1061,"user":{"displayName":"ANTAREEP GHOSH","userId":"15312027929172890356"}},"outputId":"7fecb377-2f27-4aba-c0e5-dffa9bf3a06f"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean cross-validated score of the best model: 0.9808\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n","  _data = np.array(data, dtype=dtype, copy=copy,\n"]}]},{"cell_type":"code","source":["# Step 1: Download the dataset\n","!gdown --id 1qUa1GlG4X4ZY_4E0e7jPR-z7AG7NIDbE -O Social_Network_Ads.csv\n","\n","# Step 2: Import necessary libraries\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","\n","# Load the dataset\n","data = pd.read_csv(\"Social_Network_Ads.csv\")\n","\n","# Step 3: Split the data into features (X) and target (y)\n","X = data.drop(columns=['Purchased'])  # Replace 'Purchased' with the actual target column name\n","y = data['Purchased']\n","\n","# Step 4: Split the dataset into training and testing sets with a 75:25 ratio\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n","\n","# Step 5: Standardize the feature matrix\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","# Step 6: Initialize and train the linear SVM model\n","model = SVC(kernel='linear', random_state=0)\n","model.fit(X_train, y_train)\n","\n","# Step 7: Make predictions on the test set\n","y_pred = model.predict(X_test)\n","\n","# Step 8: Calculate accuracy score\n","accuracy = accuracy_score(y_test, y_pred)\n","\n","# Step 9: Calculate the confusion matrix\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","\n","# Display the results\n","print(f\"Accuracy Score: {accuracy:.4f}\")\n","print(\"Confusion Matrix:\")\n","print(conf_matrix)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RdmgQZf9dtzi","executionInfo":{"status":"ok","timestamp":1731852831966,"user_tz":-330,"elapsed":4970,"user":{"displayName":"ANTAREEP GHOSH","userId":"15312027929172890356"}},"outputId":"9e3b4028-9579-4011-c306-de80173af892"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  warnings.warn(\n","Downloading...\n","From: https://drive.google.com/uc?id=1qUa1GlG4X4ZY_4E0e7jPR-z7AG7NIDbE\n","To: /content/Social_Network_Ads.csv\n","100% 4.90k/4.90k [00:00<00:00, 16.3MB/s]\n","Accuracy Score: 0.9000\n","Confusion Matrix:\n","[[66  2]\n"," [ 8 24]]\n"]}]},{"cell_type":"code","source":["from sklearn.datasets import fetch_openml\n","from sklearn.pipeline import Pipeline\n","from sklearn.svm import SVC\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n","\n","# Step 1: Load the MNIST dataset\n","mnist = fetch_openml('mnist_784', version=1)\n","\n","# Step 2: Split the dataset into training and test data\n","X = mnist.data\n","y = mnist.target\n","\n","# Using the first 20,000 samples as training data and the next 5,000 as test data\n","X_train, y_train = X[:20000], y[:20000]\n","X_test, y_test = X[20000:25000], y[20000:25000]\n","\n","# Step 3: Create a pipeline with MinMaxScaler and SVC with specified parameters\n","pipeline = Pipeline([\n","    ('scaler', MinMaxScaler()),\n","    ('svc', SVC(kernel='linear', decision_function_shape='ovr', class_weight=None, random_state=0))\n","])\n","\n","# Step 4: Fit the pipeline on the training data\n","pipeline.fit(X_train, y_train)\n","\n","# Step 5: Predict on the test data\n","y_pred = pipeline.predict(X_test)\n","\n","# Step 6: Calculate the confusion matrix\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","\n","# Calculate the sum of the main diagonal elements of the confusion matrix\n","diagonal_sum = conf_matrix.trace()\n","\n","# Step 7: Calculate precision, recall, and F1 score\n","precision = precision_score(y_test, y_pred, average='macro')\n","recall = recall_score(y_test, y_pred, average='macro')\n","f1 = f1_score(y_test, y_pred, average='macro')\n","\n","# Display the results\n","print(f\"Sum of the main diagonal elements of the confusion matrix: {diagonal_sum}\")\n","print(f\"Precision: {precision:.4f}\")\n","print(f\"Recall: {recall:.4f}\")\n","print(f\"F1 Score: {f1:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AfqXcUOfekeh","executionInfo":{"status":"ok","timestamp":1731852988584,"user_tz":-330,"elapsed":68439,"user":{"displayName":"ANTAREEP GHOSH","userId":"15312027929172890356"}},"outputId":"d68b1475-af5d-4861-882b-3c51e7ba9233"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Sum of the main diagonal elements of the confusion matrix: 4623\n","Precision: 0.9240\n","Recall: 0.9234\n","F1 Score: 0.9233\n"]}]},{"cell_type":"code","source":["from sklearn.datasets import fetch_openml\n","from sklearn.pipeline import Pipeline\n","from sklearn.svm import SVC\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import classification_report\n","from sklearn.model_selection import train_test_split\n","\n","# Step 1: Load the MNIST dataset\n","mnist = fetch_openml('mnist_784', version=1)\n","X = mnist.data\n","y = mnist.target\n","\n","# Step 2: Split the data into training and test sets with a 50:50 ratio and random_state=42\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n","\n","# Step 3: Create a pipeline with StandardScaler and SVM classifier with specified parameters\n","pipeline = Pipeline([\n","    ('scaler', StandardScaler()),\n","    ('svc', SVC(kernel='poly', degree=3, decision_function_shape='ovr', class_weight='balanced', C=10, random_state=0))\n","])\n","\n","# Step 4: Train the model on the training data\n","pipeline.fit(X_train, y_train)\n","\n","# Step 5: Make predictions on the test data\n","y_pred = pipeline.predict(X_test)\n","\n","# Step 6: Generate the classification report\n","report = classification_report(y_test, y_pred, output_dict=True)\n","weighted_f1_score = report['weighted avg']['f1-score']\n","\n","# Display the results\n","print(f\"Weighted average F1 score: {weighted_f1_score:.4f}\")\n","print(\"Full Classification Report:\")\n","print(classification_report(y_test, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Guo8DZL6fLkz","executionInfo":{"status":"ok","timestamp":1731853582398,"user_tz":-330,"elapsed":505247,"user":{"displayName":"ANTAREEP GHOSH","userId":"15312027929172890356"}},"outputId":"eab9a83a-b8cf-4468-8164-8830d542b60d"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Weighted average F1 score: 0.9723\n","Full Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.99      0.98      0.99      3463\n","           1       0.99      0.99      0.99      3927\n","           2       0.96      0.97      0.96      3520\n","           3       0.98      0.96      0.97      3551\n","           4       0.96      0.98      0.97      3333\n","           5       0.97      0.97      0.97      3144\n","           6       0.98      0.98      0.98      3490\n","           7       0.98      0.97      0.97      3718\n","           8       0.96      0.96      0.96      3344\n","           9       0.96      0.96      0.96      3510\n","\n","    accuracy                           0.97     35000\n","   macro avg       0.97      0.97      0.97     35000\n","weighted avg       0.97      0.97      0.97     35000\n","\n"]}]}]}